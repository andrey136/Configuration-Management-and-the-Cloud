# Configuration-Management-and-the-Cloud
Writing of lectures

## Automating with Configuration Management

### What is scale?

In this course we'll focus on making our work scale. So what do we mean when we talk about scale? **Being able to scale what we do means that we can keep achieving larger impacts with the same amount of effort when a system scales**. Well an increase in the amount of work it needs to do can be accommodated by an increase in capacity. For example, if the web application your company provides is scalable, that it can handle an increase in the number of people using it by adding more servers to serve requests. In short, a scalable system is a flexible one. Adding more computers to the pool of servers that are serving the website can be a very simple or very hard operation depending on how your infrastructure is set up. To figure out how scalable your current setup is, you can ask yourself questions like will adding more servers increase the capacity of the service? How are new servers prepared, installed, and configured? How quickly can you set up new computers to get them ready to be used? Could you deploy a hundred servers with the same IT team that you have today? Or would you need to hire more people to get it done faster? Would all the deployed servers be configured exactly the same way? Scaling isn't just about website serving content of course. If your company is rapidly hiring a lot of new employees, you'll need to have an onboarding process that can scale as needed. And as you keep adding new computers to the network, you'll need to make sure that your system administration process can scale to the growing needs of the company. This can include tasks like a applying the latest security policies and patches while making sure users' needs still get addressed all while more and more users join the network without new support staff to back you up. If making this happen sounds a bit like magic right now, remember that we're here to share the secret ingredient with you, automation. **Automation is an essential tool for keeping up with the infrastructure needs of a growing business.** By using the right automation tools, we can get a lot more done in the same amount of time. For example, we could deploy a whole new server by running a single command and letting the automation take care of the rest. We could also create a batch of user accounts with all the necessary permissions based on data already stored in the database, eliminating all human interaction. Automation is what lets us scale. It allows a small IT team to be in charge of hundreds or even thousands of computers. Okay, so what does that look like in practice? There's a bunch of different tools that we can use to achieve this. Up next, we'll talk about a type of tool called configuration management that can help us automate how we manage the computers in our fleets.

### What is configuration management?

Imagine your team is in charge of setting up a new server. This could be a physical computer running close to you or a virtual machine running somewhere in the cloud. To get things moving, the team installs the operating system, configures some applications and services, sets up the networking stack, and when everything is ready, puts the server into use. By manually deploying the installation and configuring the computer, we see that we're using unmanaged configuration. When we say configuration here, we're talking about everything from the current operating system and the applications installed to any necessary configuration files or policies, including anything else that's relevant for the server to do its job. When you work in IT, you're generally in charge of the configuration of a lot of different devices, not just servers. Network routers printers and even smart home devices can have configuration that we can control. For example, a network switch might use a config file to set up each of its ports. All right, so now we know what we mean when we talk about configuration. We said that manually deploying a server means that the configuration is unmanaged. **So what would it mean for the configuration to be managed? It means using a configuration management system to handle all of the configuration of the devices in your fleet, also known as nodes.** There's a bunch of different tools available depending on the devices and services involved. Typically you'll define a set of rules that have to be applied to the nodes you want to manage and then have a process that ensures that those settings are true on each of the nodes. At a small scale, unmanaged configurations seem inexpensive. If you only manage a handful of servers, you might be able to get away with doing that without the help of automation. You could log into each device and make changes by hand when necessary. And when your company needs a new database server, you might just go ahead and manually install the OS and the database software into a spare computer. But this approach doesn't always scale well. The more servers that you need to deploy, the more time it will take you to do it manually. And when things go wrong, and they often do, it can take a lot of time to recover and have the servers back online. Configuration management systems aim to solve this scaling problem. By managing the configuration of a fleet with a system like this, large deployments become easier to work with because the system will deploy the configuration automatically no matter how many devices you're managing. When you use configuration management and you need to make a change in one or more computers, you don't manually connect to each computer to perform operations on it. Instead, you edit the configuration management rules and then let the automation apply those rules in the affected machines. This way the changes you make to a system or group of systems are done in a systematic, repeatable way. Being repeatable is important because it means that the results will be the same on all the devices. A configuration management tool can take the rules you define and apply them to the systems that it manages, making changes efficient and consistent. Configuration management systems often also have some form of automatic error correction built in so that they can recover from certain types of errors all by themselves. For example, say you found that some application that was being used widely in your company was configured to be very insecure. You can add rules to your configuration management system to improve the settings on all computers. And this won't just apply the more secure settings once. It will continue to monitor the configuration going forward. If a user changes the settings on their machine, the configuration management tooling will detect this change and reapply the settings you defined in code. How cool is that? **There are lots of configuration management systems available in the IT industry today. Some popular systems include Puppet, Chef, Ansible, and CFEngine.** These tools can be used to manage locally hosted infrastructure. Think bare metal or virtual machines, like the laptops or work stations that employees use at a company. Many also have some kind of Cloud integration allowing them to manage resources in Cloud environments like Amazon EC2, Microsoft Azure, or the Google Cloud platform, and the list doesn't stop there. There are some platform specific tools, like SCCM and Group Policy for Windows. These tools can be very useful in some specific environments, even when they aren't as flexible as the others. For this course, we've chosen to focus on Puppet because it's the current industry standard for configuration management. Keep in mind though that selecting a configuration management system is a lot like deciding on a programming language or version control system. You should pick the one that best fits your needs and adapt accordingly, if necessary. Each has its own strengths and weaknesses. So a little research beforehand can help you decide which system is best suited for your particular infrastructure needs. There are a lot of tools out there. So be sure to check them out. Up next, we'll discuss how we can make the most out of our configuration management system using the infrastructure as code paradigm.

### What is infrastructure as code?

We've called out that when we use a configuration management system, we write rules that describe how the computers in our fleet should be configured. These rules are then executed by the automation, to make the computers match our desired state. This means that we can model the behavior of our IT infrastructure in files that can be processed by automatic tools. These files can then be tracked in a version control system. Remember, version control systems help us keep track of all changes done to the files, helping answer questions like who, when, and why. More importantly, they're super-useful when we need to revert changes. This can be especially helpful if a change turns out to be problematic. **The paradigm of storing all the configuration for the managed devices in version controlled files is known as Infrastructure as Code or IaC.** In other words, we see that we're using Infrastructure as Code when all of the configuration necessary to deploy and manage a node in the infrastructure is stored in version control. This is then combined with automatic tooling to actually get the nodes provisioned and managed. If you have all the details of your Infrastructure properly stored in the system, you can very quickly deploy a new device if something breaks down. Simply get a new machine, either virtual or physical, use the automation to deploy the necessary configuration, and you're done. **The principals of Infrastructure as Code are commonly applied in cloud computing environments, where machines are treated like interchangeable resources, instead of individual computers. This principle is also known as treating your computers as cattle instead of pets because you care for them as a group rather than individually.** Apologies to anyone with a pet cow. This concept isn't just for managing computers in huge data centers or globe spanning infrastructures, it can work for anything; from servers to laptops, or even workstations in a small IT department. Even if your company only has a single computer working as the mail server, you can still benefit from storing all the configuration needed to set it up in a configuration management system. That way if the server ever stops working, you can deploy a replacement very quickly by simply applying the rules that configure the mail server to the new computer. One valuable benefit of this process is that the configuration applied to the device doesn't depend on a human remembering to follow all the necessary steps. Rest assured, silly human, the result will always be the same, making the deployment consistent. As mentioned, having Infrastructure as Code means that we can also apply the benefits of the version control system or VCS to your infrastructure. Since the configuration of our computers is stored in files, those files can be added to a VCS. This has all the benefits that version control systems bring. It gives us an audit trail of changes, it lets us quickly rollback if a change was wrong, it lets others reviewed our code to catch errors and distribute knowledge, it improves collaboration with the rest of the team, and it lets us easily check out the state of our infrastructure by looking at the rules that are committed. Not too shabby. I personally think this is one of the coolest things about IaC. The ability to easily see what configuration changes were made and roll back to a known good state is super important. It can make a big difference in quickly recovering from an outage, especially since changing the contents of the configuration file can be as dangerous as updating the version of an application. I've had my fair share of outages caused by an innocent-looking change with unintended side effects. But storing all the infrastructure in a version control system lets me quickly roll back to a previously known good version so that the outage length can be minimized. On top of that, having the rules stored in files means that we can also run automated tests on them. It's much better to find out in a test that a configuration file has a typo in it than to find out from our users. In a complex or large environment, treating your IT Infrastructure as Code can help you deploy a flexible scalable system. A configuration management system can help you manage that code by providing a platform to maintain and provision that infrastructure in an automated way. Having your infrastructure stored as code means that you can automatically deploy your infrastructure with very little overhead. If you need to move it to a different location, it can be deployed, de-provisioned, and redeployed at scale in a different locale with minimal code level changes. **To sum all of this up, managing your Infrastructure as Code it means that your fleet of nodes are consistent, versioned, reliable, and repeatable.** Instead of being seen as precious or unique, machines are treated as replaceable resources that can be deployed on-demand through the automation. Any infrastructure that claims to be scalable must be able to handle the capacity requirements of growth. Performing an action like adding more servers to handle an increase in requests is just a possible first step. There are other things that we might need to take into account, such as the amount of traffic that network can handle or the load on the back end servers like databases. Viewing your infrastructure in this way helps your IT team adapt and stay flexible. The technology industry is constantly changing and evolving. Automation and configuration management can help you embrace that change instead of avoiding it. Before diving into concrete examples of what this looks like, the first practice quiz of the course is coming up. These quizzes act as check-in points to help you make sure all the concepts covered in the videos are making sense. See you on the other side.

### What is Puppet?

As we called out a couple of times already, in this course, we'll be learning how to apply basic configuration management concepts by using Puppet. **Puppet is the current industry standard for managing the configuration of computers in a fleet of machines.** Part of the reason why Puppet is so popular is that it's a cross-platform tool that's been around for a while. It's an open source project that was created in 2005, and it's gone through several different versions. As it's evolved, the tool has incorporated feedback from its users to make it more and more useful. The latest available version at the time this Google course went live is Puppet 6, which came out in late 2018. **We typically deploy puppet using a client-server architecture. The client is known as the Puppet agent, and the service is known as the Puppet master.** When using this model, the agent connects to the master and sends a bunch of facts that describe the computer to the master. The master then processes this information, generates the list of rules that need to be applied on the device, and sends this list back to the agent. The agent is then in charge of making any necessary changes on the computer. **Puppet is a cross-platform application available for all Linux distributions, Windows, and Mac OS. This means that you can use the same puppet rules for managing a range of different computers.** What are these rules that we keep talking about? Let's check out a very simple example. This block is saying that the package 'sudo' should be present on every computer where the rule gets applied. If this rule is applied on 100 computers, it would automatically install the package in all of them. This is a small and simple block but can already give us a basic impression of how rules are written in puppet. Don't worry too much about the syntax now, we'll look into what each piece means in future videos. There are various installation tools available depending on the type of operating system. Puppet will determine the type of operating system being used and select the right tool to perform the package installation. **On Linux distributions, there are several package management systems like APT, Yum, and DNF.** Puppet will also determine which package manager should be used to install the package. On Mac OS, there's a few different available providers depending on where the package is coming from. **The Apple Provider is used for packages that are part of the OS, while the MacPorts provider is used for packages that come from the MacPorts Project. For Windows, we'll need to add an extra attribute to our rule, stating where the installer file is located on the local desk or a network mounted resource.** Puppet will then execute the installer and make sure that it finishes successfully. If you use Chocolatey to manage your windows packages, you can add an extra Chocolatey provider to Puppet to support that. We'll add a link to more information about this in our next reading. **Using rules like this one, we can get puppet to do a lot more than just install packages for us. We can add, remove, or modify configuration files stored in the system, or change registry entries on Windows. We can also enable, disable, start, or stop the services that run on our computer.** We can configure crone jobs, the scheduled tasks, add, remove, or modify Users and Groups or even execute external commands, if that's what we need. There's a lot to say about puppet. We won't go into absolutely every detail, but we'll cover the most important concepts in this course. The goal is to get you started with what you need to know about configuration management in general and puppet in particular. We'll also give you pointers to find out more information on your own. Up next, we'll check out the different resources we can use to define our rules.

### Puppet Resources

In our last video, we saw an example that installed the pseudo package in a computer. To do that, our example used the package keyword declaring a package resource. **In puppet, resources are the basic unit for modeling the configuration that we want to manage. In other words, each resource specifies one configuration that we're trying to manage, like a service, a package, or a file.** Let's look at another example. In this case, we're defining a file resource. This resource type is used for managing files and directories. In this case, it's a very simple rule that ensures that etc/sysctl.d exists and is a directory. Let's talk a little bit about syntax. In both our last example and this one we could see that when declaring a resource in puppet, we write them in a block that starts with the resource type ,in this case File. The configuration of the resource is then written inside a block of curly braces. Right after the opening curly brace, we have the title of the resource, followed by a colon. After the colon come the attributes that we want to set for the resource. In this example, we're once again setting the insurer attribute with directory as the value, but we could set other attributes too >> Let's check out a different file resource. In this example, we're using a file resource to configure the contents of etc/timezone, a file, that's used in some Linux distributions to determine the time zone of the computer. This resource has three attributes. First, we explicitly say that this will be a file instead of a directory or a symlink then we set the contents of the file to the UTC time zone. Finally, we set the replace attribute to true, which means that the contents of the file will be replaced even if the file already exists. We've now seen a couple examples of what we can do with the file resource. There are a lot more attributes that we could set, like file permissions the file owner, or the file modification time.
We've included a link to the official documentation in the next reading where you can find all the possible attributes that can be set for each resource. How do these rules turn into changes in our computers? When we declare a resource in our puppet rules. We're defining the desired state of that resource in the system. The puppet agent then turns the desired state into reality using providers.
**The provider used will depend on the resource defined and the environment where the agent is running.** Puppet will normally detect this automatically without us having to do anything special. When the puppet agent processes a resource, it first decides which provider it needs to use, then passes along the attributes that we configured in the resource to that provider. **The code of each provider is in charge of making our computer reflect the state requested in the resource.** In these examples, We've looked at one resource at a time. Up next, we'll see how we can combine a bunch of resources into more complex puppet classes.

### Puppet Classes

In the examples of Puppet code that we've seen so far, we've declared classes that contain one resource. You might have wondered what those classes were for. We use these classes to collect the resources that are needed to achieve a goal in a single place. For example, you could have a class that installs a package, sets the contents of a configuration file, and starts the service provided by that package. Let's check out an example like that. In this case, we have a class with three resources, a package, a file, and a service. All of them are related to the Network Time Protocol, or NTP, the mechanism our computers use to synchronize the clocks. Our rules are making sure that the NTP package is always upgraded to the latest version. We're setting the contents of the configuration file using the source attribute, which means that the agent will read the required contents from the specified location. And we're saying that we want the NTP service to be enabled and running. By grouping all of the resources related to NTP in the same class, we only need a quick glance to understand how the service is configured and how it's supposed to work. This would make it easier to make changes in the future since we have all the related resources together. It makes sense to use this technique whenever we want to group related resources. For example, you could have a class grouping all resources related to managing log files, or configuring the time zone, or handling temporary files and directories. You could also have classes that group all the settings related to your web serving software, your email infrastructure, or even your company's firewall. We're just getting started with Puppet's basic resources and seeing how they can be applied. In further videos, we'll be learning a lot more about common practices when using configuration management tools. But before jumping into that, we've put together a reading with more information about Puppet syntax, resources and links to the official reference. Then we've got a quick quiz to check that everything is making sense.
**By grouping related resources together, we can more easily understand the configuration and make changes in the future.**

### Links 

Check out the following links for more information:

https://puppet.com/docs/puppet/latest/lang_resources.html
https://puppet.com/blog/deploy-packages-across-your-windows-estate-with-bolt-and-chocolatey/

### What are domain-specific languages?

Up until now, we've seen examples of very simple Puppet rules they just define whiner more resources. **These resources are the building blocks of Puppet rules, but we can do much more complex operations using Puppet's domain specific language or DSL.** **Typical programming languages like Python, Ruby, Java or Go are general purpose languages that can be used to write lots of different applications with different goals and use cases.** On the flip side, **a domain specific language is a programming language that's more limited in scope.** Learning a domain-specific language is usually much faster and easier than learning a general purpose programming language because there's a lot less to cover. You don't need to learn as much syntax or understand as many keywords or taking to account a lot of overhead in general. In the case of Puppet, the DSL is limited to operations related to when and how to apply configuration management rules to our devices. For example, we can use the mechanisms provided by the DSL to set different values on laptops or desktop computers, or to install some specific packages only on the company's web servers. On top of the basic resource types that we already checked out, Puppet's DSL includes variables, conditional statements, and functions. Using them, we can apply different resources or set attributes to different values depending on some conditions. Before we jump into an example of what that looks like, let's talk a bit about **Puppet facts. Facts are variables that represent the characteristics of the system.** __When the Puppet agent runs, it calls a program called factor which analyzes the current system, storing the information it gathers in these facts.__ Once it's done, it sends the values for these facts to the server, which uses them to calculate the rules that should be applied. Puppet comes with a bunch of baked-in core facts that store useful information about the system like what the current OS is, how much memory the computer has whether it's a virtual machine or not or what the current IP address is. If the information we need to make a decision isn't available through one of these facts, we can also write a script that checks for the information and turns it into our own custom fact. Let's check out an example of a piece of Puppet code that makes use of one of the built-in facts. **This piece of code is using the is-virtual fact together with a conditional statement to decide whether the smartmontools package should be installed or purged. This package is used for monitoring the state of hard drives using smart.** So it's useful to have it installed in physical machines, but it doesn't make much sense to install it in our virtual machines. We can see several of the characteristics of Puppets domain specific language in this block. So let's spend a little time looking at all of the elements of syntax here. First, facts is a variable. All variable names are preceded by a dollar sign in Puppet's DSL. **In particular, the facts variable is what's known as a hash in the Puppet DSL, which is equivalent to a dictionary in Python.** This means that we can access the different elements in the hash using their keys. In this case, we're accessing the value associated to the is virtual key. Second, we see how we can write a conditional statement using if else, enclosing each block of the conditional with curly braces. Finally, each conditional block contains a package resource. We've seen resources before, but we haven't looked at the syntax in detail. So let's do that now. Every resource starts with the type of resource being defined. In this case, package and the contents of the resource are then enclosed in curly braces. Inside the resource definition, the first line contains the title followed by a colon. Any lines after that are attributes that are being set. We use equals greater than to assign values to the attributes and then each attribute ends with a comma. We've now covered a large chunk of puppet's DSL syntax. If you look back to what it was like to learn your first programming language, you'll probably notice how much less syntax there is to learn here. That's typical of the domain specific languages used by configuration management tools. While each tool uses their own DSL, they're usually very simple and can be learned very quickly. Up next, we'll talk about a few other principles behind most configuration management tools. Whenever you're ready, let's dive in.
**A fact is a hash that stores information about the details of a particular system.**

### The Driving Principles of Configuration Management

Up to now, we've seen a few examples of what Puppet rules look like, including a bunch of different resources and even a conditional expression. You might have noticed that in all the examples we've checked out, we were never telling the computer the steps it should follow in order to do what we wanted. Instead, we were just declaring the end goal that we wanted to achieve, like going to a drive-through and ordering a burger, we didn't make it, but there it is. **The providers that we mentioned earlier lake apt and yum are the ones in charge of turning our goals into whatever actions are necessary.** We say that Puppet uses a **declarative language** because we declare the state that we want to achieve rather than the steps to get there. **Traditional languages like Python or C are called procedural because we write out the procedure that the computer needs to follow to reach our desired goal.** Coming from a procedural language like Python, it might take some time to get used to writing declarative code like the ones used for Puppet, and that's okay. Just remember that when it comes to configuration management, it makes sense to simply state what the configuration should be, not what the computer should do to get there. Say you're using a resource to declare that you want a package installed, you don't care what commands a computer has to run you install it, you only care that after the configuration management tool has run, the package is installed. **Another important aspect of configuration management is that operations should be idempotent. In this context, an idempotent action can be performed over and over again without changing the system after the first time the action was performed, and with no unintended side effects.** Let's check this out with an example of a file resource. This resource ensures that the /etc/issue file has a set of permissions and a specific line in it. Fulfilling this requirement is an idempotent operation. If the file already exists and has the desired content, then Puppet will understand that no action has to be taken. If the file doesn't exist, then puppet will create it. If the contents or permissions don't match, Puppet will fix them. No matter how many times the agent applies the rule, the end result is that this file will have the requested contents and permissions. **Idempotency is a valuable property of any piece of automation. If a script is idempotent, it means that it can fail halfway through its task and be run again without problematic consequences.** Say you're running your configuration management system to setup a new server. Unfortunately, the setup fails because you forgot to add a second disk to the computer and the configuration required two disks. If your automation is idempotent, you can add the missing disk and then have the system pick up from where it left off. Most Puppet resources provide idempotent actions, and we can rest assured that two runs of the same set of rules will lead to the same end result. **An exception to this is the exec resource, which runs commands for us.** The actions taken by the exec resource might not be idempotent since a command might modify the system each time it's executed. To understand this, let's check out what happens when we execute a command that moves a file on our computer. First, we'll check that the example.txt file is here, and then we'll move it to the desktop directory.
This works fine now, but what happens if we run the exact same command again after it's been executed once? **We receive an error because the file is no longer in the same place. In other words, this was not an idempotent action, as executing the same action twice produced a different result and the unintended side effect of an error.** If we were running this inside Puppet, this would cause our Puppet run to finish with an error. So if we need to use the exec resource to run a command for us, we need to be careful to ensure that the action is idempotent. **We could do that for example by using the onlyif attribute like this. Using the onlyif attribute, we specified that this command should be executed only if the file that we want to move exists. This means that the file will be moved if it exists and nothing will happen if it doesn't.** By adding this conditional, we've taken an action that's not idempotent and turned it into an idempotent one. Another important aspect of how configuration management works is the **test and repair paradigm. This means that actions are taken only when they are necessary to achieve a goal.** Puppet will first test to see if the resource being managed like a file or a package, actually needs to be modified. If the file exists in the place we want it to, no action needs to be taken. If a package is already installed, there's no need to install it again. This avoids wasting time doing actions that aren't needed. Finally, another **important characteristic is that Puppet is stateless, this means that there's no state being kept between runs of the agent.** Each Puppet run is independent of the previous one, and the next one. **Each time the puppet agent runs, it collects the current facts. The Puppet master generates the rules based just on those facts, and then the agent applies them as necessary.** We're just getting started with what configuration management is and what it looks like in Puppet. But hopefully, you're starting to see how understanding these basic concepts and how turning them into practical rules can help you manage a small army of computers. Up next, there's a reading with links to more information about the concepts we've covered followed by a quick quiz. You've got this.

### Links 

Check out the following links for more information:

https://en.wikipedia.org/wiki/Domain-specific_language
http://radar.oreilly.com/2015/04/the-puppet-design-philosophy.html


### Module 1 Wrap Up: Automating with Configuration Management

We started our journey talking about what would happen if you needed to upgrade a package in a fleet of 1,000 different servers. If you've never heard about configuration management before, an upgrade like that probably seemed like a super long and boring task, right? But now you know that there's a bunch of tools you can use to make your life much easier when making large-scale changes like that one. We've talked about the automation that's necessary for provisioning, managing and adapting a fleet of computers in a scalable way. **We called out that an important concept in today's IT world is to treat our infrastructure as code. This lets us manage our fleet of computers in a consistent, versionable, reliable and repeatable way.** To figure out how to get there, we've covered a lot of concepts related to configuration management, like how these tools use a domain specific language to help us clearly state what we want our system to look like after the tools have run. We've mentioned that the language is declarative because we declare our goals rather than detail the steps to get there, and most importantly the actions taken must be idempotent so that several runs of the same rules always lead to the same results. All along, we've been using Puppet as an example of how configuration management tools work. We looked into the puppet DSL syntax and checked out the most common resources: packages, files and services. We'll learn about other resources and other advanced techniques in future videos. But by now you should have a pretty good idea of what Puppet rules look like and how you can put into action the configuration management concepts that we discussed. With the concepts we've covered, you're probably starting to see how keeping your fleet of machines, whether they're virtual or physical, off of a pedestal is good practice. If something breaks, goes down or catches fire literally or figuratively, you can easily spin up a replacement because you know exactly what it's supposed to look like from the configuration and you can deploy it easily using the automation. In the next module, we'll check out how you can deploy Puppet in your infrastructure and look into some more advanced configuration management and change management techniques. Before that, you'll have the opportunity to try out fixing a system where the configuration management isn't doing what it's supposed to. You'll see what running the Puppet agent looks like in practice and find out what's wrong with the deployed rules, and then get the automation to behave as expected. Cool, right? Let's go for it.

